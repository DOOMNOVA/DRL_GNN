{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from distutils.util import strtobool\n",
    "import highway_env\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "#import pybullet_envs  # noqa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from stable_baselines3.common.buffers import GraphReplayBuffer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from graph_generator import create_whole_ego_bigraph_tensor_dynamic\n",
    "#import traceback\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "from utils_gnn import load_model\n",
    "#import pygame\n",
    "import torch.multiprocessing as mp\n",
    "from torch.profiler import profiler, ProfilerActivity\n",
    "import os \n",
    "from IPython import display as ipythondisplay\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from pathlib import Path\n",
    "import base64\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \n",
    "    # fmt: off\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--exp-name\", type=str, default=os.path.basename(__file__).rstrip(\".py\"),\n",
    "    #     help=\"the name of this experiment\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=42,\n",
    "        help=\"seed of the experiment\")\n",
    "    parser.add_argument(\"--torch-deterministic\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"if toggled, `torch.backends.cudnn.deterministic=False`\")\n",
    "    parser.add_argument(\"--cuda\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"if toggled, cuda will be enabled by default\")\n",
    "    # parser.add_argument(\"--track\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
    "    #     help=\"if toggled, this experiment will be tracked with Weights and Biases\")\n",
    "    # parser.add_argument(\"--wandb-project-name\", type=str, default=\"SAC_GNN\",\n",
    "    #     help=\"the wandb's project name\")\n",
    "    # parser.add_argument(\"--wandb-entity\", type=str, default=None,\n",
    "    #     help=\"the entity (team) of wandb's project\")\n",
    "    # parser.add_argument(\"--capture-video\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
    "    #     help=\"whether to capture videos of the agent performances (check out `videos` folder)\")\n",
    "\n",
    "    # Algorithm specific arguments\n",
    "    parser.add_argument(\"--env-id\", type=str, default=\"highway-v0\",\n",
    "        help=\"the id of the environment\")\n",
    "    parser.add_argument(\"--total-timesteps\", type=int, default=1000001,\n",
    "        help=\"total timesteps of the experiments\")\n",
    "    parser.add_argument(\"--buffer-size\", type=int, default=int(1e6),\n",
    "        help=\"the replay memory buffer size\")#1e6\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.99,\n",
    "        help=\"the discount factor gamma\")\n",
    "    parser.add_argument(\"--tau\", type=float, default=0.005,\n",
    "        help=\"target smoothing coefficient (default: 0.005)\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=256,\n",
    "        help=\"the batch size of sample from the reply memory\")\n",
    "    parser.add_argument(\"--learning-starts\", type=int, default= 100,\n",
    "        help=\"timestep to start learning\")#5e3,15000\n",
    "    parser.add_argument(\"--policy-lr\", type=float, default=3e-4,\n",
    "        help=\"the learning rate of the policy network optimizer\")\n",
    "    parser.add_argument(\"--q-lr\", type=float, default=3e-4,\n",
    "        help=\"the learning rate of the Q network network optimizer\")#1e-3\n",
    "    parser.add_argument(\"--policy-frequency\", type=int, default=15,\n",
    "        help=\"the frequency of training policy (delayed)\")\n",
    "    parser.add_argument(\"--target-network-frequency\", type=int, default=1, # Denis Yarats' implementation delays this by 2.\n",
    "        help=\"the frequency of updates for the target nerworks\") #train frequency in sb3 IT IS 1\n",
    "    parser.add_argument(\"--noise-clip\", type=float, default=0.5,\n",
    "        help=\"noise clip parameter of the Target Policy Smoothing Regularization\")\n",
    "    parser.add_argument(\"--alpha\", type=float, default=0.5,\n",
    "            help=\"Entropy regularization coefficient.\")\n",
    "    parser.add_argument(\"--autotune\", type=lambda x:bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"automatic tuning of the entropy coefficient\")\n",
    "    parser.add_argument(\"--dropout\",type=float,default=0.5,\n",
    "        help=\"dropout for the GNN layers\")\n",
    "    parser.add_argument(\"--vehicles-count\",type=int,default=25,\n",
    "        help=\"number of vehicles\")\n",
    "    \n",
    "    # rewards\n",
    "    # parser.add_argument(\"--high-speed-reward\",type=float,default=0.7,\n",
    "    #     help=\"reward for high speed\")\n",
    "    # parser.add_argument(\"--on-road-reward\",type=float,default=0.2,\n",
    "    #     help=\" on road reward\")\n",
    "    # parser.add_argument(\"--collision-reward\",type=float,default=-1,\n",
    "    #     help=\"penalty for collisons\")\n",
    "    # parser.add_argument(\"--lane-change-reward\",type=float,default=0.1,\n",
    "    #     help=\"rewarding while changing lanes\")\n",
    "    # parser.add_argument(\"--right-lane-reward\",type=float,default=0.1,\n",
    "    #     help=\"reward for driving in the right lane. useful for exit ramp scenario\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    # fmt: on\n",
    "    return args\n",
    "\n",
    "\n",
    "def make_env(env_id, seed):\n",
    "    #def thunk():\n",
    "    env = gym.make(env_id)\n",
    "    env.configure({\n",
    "     \n",
    "    #\"import_module\": \"highway_env\",\n",
    "    \"observation\" : { \"type\" : \"Kinematics\",\n",
    "                     \"vehicles_count\" :25,\n",
    "                     \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\", \"cos_h\", \"sin_h\",\"heading\",\"long_off\",\"lat_off\",\"ang_off\"],\n",
    "                    # \"features_range\": {\n",
    "                    #     \"x\": [-100, 100],\n",
    "                    #     \"y\": [-100, 100],\n",
    "                    #     \"vx\": [-20, 25],\n",
    "                    #     \"vy\": [-20, 25]  },\n",
    "                    \"absolute\" : True,\n",
    "                    \"order\" : \"sorted\",\n",
    "                    \"on_road\" :  True,\n",
    "                     \"normalize\" : True,\n",
    "                       \n",
    "        },\n",
    "    \"action\": {\n",
    "        \"type\": \"ContinuousAction\",\n",
    "        \"acceleration_range\" : [-3.5,3.5],\n",
    "        \"steering_range\" : [-np.pi/18,np.pi/18],\n",
    "        'lateral' : True,\n",
    "        'longitudinal': True,\n",
    "        \"speed_range\" : [20,25],    \n",
    "        \n",
    "    }, #'offscreen_rendering': True,\n",
    "        'offroad_terminal': True,\n",
    "        \"normalize_reward\" : True,\n",
    "        \"simulation_frequency\": 15,\n",
    "        'high_speed_reward': 0.5,\n",
    "        'on_road_reward' : 0.1,\n",
    "        'collision_reward': -1,\n",
    "        #'right_lane_reward' : 0.1,\n",
    "        #\"high_speed_reward\": 0.4,  # The reward received when driving at full speed, linearly mapped to zero for\n",
    "                                       # lower speeds according to config[\"reward_speed_range\"].\n",
    "        \"lane_change_reward\": 0.1,\n",
    "        'reward_speed_range': [20, 25],\n",
    "        'vehicles_density' : 1,\n",
    "        \n",
    "        \"centering_position\": [0.3, 0.5],\n",
    "   \n",
    "        'other_vehicles_type': 'highway_env.vehicle.behavior.IDMVehicle',\n",
    "  \n",
    "        'scaling': 5.5,\n",
    " \n",
    "        'duration' : 200,\n",
    "        \"policy_frequency\": 15\n",
    "    })\n",
    "\n",
    "   \n",
    "        #env.reset()\n",
    "\n",
    "    #env.seed(seed)\n",
    "    env.action_space.seed(seed)\n",
    "    env.observation_space.seed(seed)\n",
    "    env.reset(seed=seed)\n",
    "    return env\n",
    "\n",
    "    #return thunk\n",
    "\n",
    "\n",
    "\n",
    "#the input should be the Data object generated from the obsevation \n",
    "#nodes - vehicles , node attributes-  kinematic features\n",
    "#node attributes - (#nodes,node attributes) , adjacency matrix -(#nodes,#nodes) , edge attributes -(# edges, #edge attributes)\n",
    "\n",
    "class SoftGATv2Network(nn.Module):\n",
    "    \"\"\" The SoftGATv2Network class is a neural network model that uses graph attention networks to process\n",
    "     input data and output a new embedding for the ego vehicle node.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,env,graph_data,device,num_heads=5,dropout=0.8):\n",
    "        super(SoftGATv2Network,self).__init__()\n",
    "        self.device = device\n",
    "        #graph_data = graph_data.to(self.device)\n",
    "        self.num_heads = num_heads\n",
    "        self.input_dim = graph_data.num_node_features\n",
    "        #num_actions = np.prod(env.action_space.shape)\n",
    "        edge_dim = graph_data.edge_attr.shape[1]\n",
    "        #output_dim = graph_data.x.shape\n",
    "        output_dim_row = graph_data.num_nodes\n",
    "        #output_dim_column = graph_data.num_node_features\n",
    "        self.output_dim_column = np.array(env.observation_space.shape).prod()\n",
    "        self.dropout = dropout\n",
    "        #self.input_dim = np.array(env.observation_space.shape).prod() + np.prod(env.action_space.shape)\n",
    "        self.conv1 = GATv2Conv(in_channels= self.input_dim, out_channels= num_heads*self.input_dim,heads=num_heads,dropout=self.dropout,edge_dim=edge_dim,add_self_loops= False)\n",
    "        \n",
    "        self.conv2 = GATv2Conv(in_channels= -1 ,out_channels=2*num_heads*self.input_dim,heads=1,dropout=self.dropout,edge_dim=edge_dim,add_self_loops=False)\n",
    "        \n",
    "        #self.conv3 = GATv2Conv(in_channels= -1,out_channels= 4*num_heads*self.input_dim,heads=1,dropout=self.dropout,edge_dim=edge_dim,add_self_loops=False)\n",
    "        \n",
    "        self.dense = nn.Sequential(nn.Linear(2*num_heads*self.input_dim,output_dim_row),nn.Dropout(dropout),\n",
    "                                   nn.Linear(output_dim_row,self.output_dim_column))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "       #handle bothe Batch of Graphs and single graph inputs \n",
    "    def forward(self,graph_data):\n",
    "        \n",
    "        \n",
    "        if isinstance(graph_data,Batch):\n",
    "            x ,edge_index,edge_attr,batch = graph_data.x , graph_data.edge_index, graph_data.edge_attr, graph_data.batch\n",
    "            #graph_batch_size = args.batch_size\n",
    "        else:\n",
    "            x ,edge_index,edge_attr = graph_data.x , graph_data.edge_index, graph_data.edge_attr\n",
    "                                                                                                                                    \n",
    "                                                                                                                                    \n",
    "        \n",
    "        x = F.relu(self.conv1(x,edge_index,edge_attr=edge_attr))\n",
    "        x = F.dropout(x,p=self.dropout,training=self.training)\n",
    "        \n",
    "        x = F.relu(self.conv2(x,edge_index,edge_attr=edge_attr))\n",
    "        x = F.dropout(x,p=self.dropout,training=self.training)\n",
    "        \n",
    "        # x = F.relu(self.conv3(x,edge_index,edge_attr=edge_attr))\n",
    "        # x = F.dropout(x,p=self.dropout,training=self.training)\n",
    "\n",
    "        #get the ego embeddings from the network\n",
    "        if isinstance(graph_data,Batch):\n",
    "            #new_ego_node_embeddings = torch.zeros((graph_data.num_graphs,4*self.num_heads*self.input_dim),device=self.device) # Shape: (batch_size, embedding_size)\n",
    "            new_ego_node_embeddings = []\n",
    "            for graph_index in torch.unique(batch):\n",
    "                graph_mask = (batch == graph_index)\n",
    "                new_ego_embed = x[graph_mask][0]\n",
    "                new_ego_node_embeddings.append(new_ego_embed)\n",
    "            new_ego_node_embeddings = torch.stack(new_ego_node_embeddings,dim=0)\n",
    "        # for a single graph input while training\n",
    "        else:\n",
    "            new_ego_node_embeddings = x[0]\n",
    "\n",
    "        #pass the ego embeddings to a dense layer\n",
    "        new_ego_node_embeddings = torch.sigmoid(self.dense(new_ego_node_embeddings))\n",
    "       \n",
    "        return new_ego_node_embeddings\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# ALGO LOGIC: initialize agent here: \n",
    "# the critic networks - Q1 and Q2 \n",
    "class SoftQNetwork_GNN(nn.Module):\n",
    "    def __init__(self, env,graph_data,device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.gat_gnn_critic = SoftGATv2Network(env,graph_data,self.device).to(self.device)\n",
    "        self.fc1 = nn.Linear(np.array(env.observation_space.shape).prod() + np.prod(env.action_space.shape), 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, a):\n",
    "        x = self.gat_gnn_critic(x)\n",
    "        x = torch.cat([x, a], 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "LOG_STD_MAX = 2\n",
    "LOG_STD_MIN = -5\n",
    "\n",
    "\n",
    "class Actor_GNN(nn.Module):\n",
    "    def __init__(self, env,graph_data,device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.gat_gnn_actor = SoftGATv2Network(env,graph_data,self.device).to(self.device)\n",
    "        self.fc1 = nn.Linear(np.array(env.observation_space.shape).prod(), 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc_mean = nn.Linear(256, np.prod(env.action_space.shape))\n",
    "        self.fc_logstd = nn.Linear(256, np.prod(env.action_space.shape))\n",
    "        # action rescaling --maybe not needed, the acceleration is less, so the ego vehicle is slow.\n",
    "        self.register_buffer(\n",
    "            \"action_scale\", torch.tensor((env.action_space.high - env.action_space.low) / 2.0, dtype=torch.float32)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"action_bias\", torch.tensor((env.action_space.high + env.action_space.low) / 2.0, dtype=torch.float32)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gat_gnn_actor(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        mean = self.fc_mean(x)\n",
    "        log_std = self.fc_logstd(x)\n",
    "        log_std = torch.tanh(log_std)\n",
    "        log_std = LOG_STD_MIN + 0.5 * (LOG_STD_MAX - LOG_STD_MIN) * (log_std + 1)  # From SpinUp / Denis Yarats\n",
    "\n",
    "        return mean, log_std\n",
    "\n",
    "    def get_action(self, x):\n",
    "        mean, log_std = self(x)\n",
    "        std = log_std.exp()\n",
    "        normal = torch.distributions.Normal(mean, std)\n",
    "        x_t = normal.rsample()  # for reparameterization trick (mean + std * N(0,1))\n",
    "        y_t = torch.tanh(x_t)\n",
    "        action = y_t * self.action_scale + self.action_bias\n",
    "        log_prob = normal.log_prob(x_t)\n",
    "        # Enforcing Action Bound\n",
    "        log_prob -= torch.log(self.action_scale * (1 - y_t.pow(2)) + 1e-6)\n",
    "        if log_prob.dim() ==1:\n",
    "            log_prob = log_prob.unsqueeze(1)\n",
    "        log_prob = log_prob.sum(1, keepdim=True)\n",
    "        mean = torch.tanh(mean) * self.action_scale + self.action_bias\n",
    "        return action, log_prob, mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def record_videos(env, video_folder=\"/Users/haridevaraj/Documents/VOLVO/Models/GNN\"):\n",
    "    wrapped = RecordVideo(env, video_folder=video_folder, episode_trigger=lambda e: True)\n",
    "\n",
    "    # Capture intermediate frames\n",
    "    env.unwrapped.set_record_video_wrapper(wrapped)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "\n",
    "def show_videos(path=\"videos\"):\n",
    "    html = []\n",
    "    for mp4 in Path(path).glob(\"*.mp4\"):\n",
    "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
    "        html.append('''<video alt=\"{}\" autoplay\n",
    "                      loop controls style=\"height: 400px;\">\n",
    "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
    "                 </video>'''.format(mp4, video_b64.decode('ascii')))\n",
    "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n",
    "\n",
    "\n",
    "# #os.environ['SDL_VIDEODRIVER'] = 'dummy'\n",
    "# #uncommnet below two line to view the vido while training\n",
    "# os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
    "# os.environ['DISPLAY'] = ':1'\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--seed SEED]\n",
      "                             [--torch-deterministic [TORCH_DETERMINISTIC]]\n",
      "                             [--cuda [CUDA]] [--env-id ENV_ID]\n",
      "                             [--total-timesteps TOTAL_TIMESTEPS]\n",
      "                             [--buffer-size BUFFER_SIZE] [--gamma GAMMA]\n",
      "                             [--tau TAU] [--batch-size BATCH_SIZE]\n",
      "                             [--learning-starts LEARNING_STARTS]\n",
      "                             [--policy-lr POLICY_LR] [--q-lr Q_LR]\n",
      "                             [--policy-frequency POLICY_FREQUENCY]\n",
      "                             [--target-network-frequency TARGET_NETWORK_FREQUENCY]\n",
      "                             [--noise-clip NOISE_CLIP] [--alpha ALPHA]\n",
      "                             [--autotune [AUTOTUNE]] [--dropout DROPOUT]\n",
      "                             [--vehicles-count VEHICLES_COUNT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"dfcb7b0e-9d2b-4f9a-b685-ef04f917f975\" --shell=9007 --transport=\"tcp\" --iopub=9009 --f=/Users/haridevaraj/Library/Jupyter/runtime/kernel-v2-143857YVyZTH5efiN.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haridevaraj/opt/anaconda3/envs/volvo/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3405: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "args = parse_args()\n",
    "exp_name = \"dddd\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "\n",
    "envs = make_env(\"highway-v0\", seed)\n",
    "     # TRY NOT TO MODIFY: start the game\n",
    "     # TRY NOT TO MODIFY: start the game\n",
    "obs,info = envs.reset(seed=seed)\n",
    "plt.imshow(envs)\n",
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haridevaraj/opt/anaconda3/envs/volvo/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:42: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (5, 5)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "def make_env(env_id, seed):\n",
    "    #def thunk():\n",
    "    env = gym.make(env_id)\n",
    "    env.configure({\n",
    "     \n",
    "    #\"import_module\": \"highway_env\",\n",
    "    \"observation\" : { \"type\" : \"Kinematics\",\n",
    "                     \"vehicles_count\" :25,\n",
    "                     \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\", \"cos_h\", \"sin_h\",\"heading\",\"long_off\",\"lat_off\",\"ang_off\"],\n",
    "                    # \"features_range\": {\n",
    "                    #     \"x\": [-100, 100],\n",
    "                    #     \"y\": [-100, 100],\n",
    "                    #     \"vx\": [-20, 25],\n",
    "                    #     \"vy\": [-20, 25]  },\n",
    "                    \"absolute\" : True,\n",
    "                    \"order\" : \"sorted\",\n",
    "                    \"on_road\" :  True,\n",
    "                     \"normalize\" : True,\n",
    "                       \n",
    "        },\n",
    "    \"action\": {\n",
    "        \"type\": \"ContinuousAction\",\n",
    "        \"acceleration_range\" : [-3.5,3.5],\n",
    "        \"steering_range\" : [-np.pi/18,np.pi/18],\n",
    "        'lateral' : True,\n",
    "        'longitudinal': True,\n",
    "        \"speed_range\" : [20,25],    \n",
    "        \n",
    "    }, #'offscreen_rendering': True,\n",
    "        'offroad_terminal': True,\n",
    "        \"normalize_reward\" : True,\n",
    "        \"simulation_frequency\": 15,\n",
    "        'high_speed_reward': 0.5,\n",
    "        'on_road_reward' : 0.1,\n",
    "        'collision_reward': -1,\n",
    "        #'right_lane_reward' : 0.1,\n",
    "        #\"high_speed_reward\": 0.4,  # The reward received when driving at full speed, linearly mapped to zero for\n",
    "                                       # lower speeds according to config[\"reward_speed_range\"].\n",
    "        \"lane_change_reward\": 0.1,\n",
    "        'reward_speed_range': [20, 25],\n",
    "        'vehicles_density' : 1,\n",
    "        \n",
    "        \"centering_position\": [0.3, 0.5],\n",
    "   \n",
    "        'other_vehicles_type': 'highway_env.vehicle.behavior.IDMVehicle',\n",
    "  \n",
    "        'scaling': 2.8,\n",
    " \n",
    "        'duration' : 200,\n",
    "        \"policy_frequency\": 15\n",
    "    })\n",
    "\n",
    "   \n",
    "        #env.reset()\n",
    "\n",
    "    #env.seed(seed)\n",
    "    env.action_space.seed(seed)\n",
    "    env.observation_space.seed(seed)\n",
    "    env.reset(seed=seed)\n",
    "    return env\n",
    "\n",
    "    #return thunk\n",
    "#env = gym.make('highway-v0', render_mode='rgb_array')\n",
    "#env.reset()\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "envs = make_env(\"highway-v0\", seed)\n",
    "     # TRY NOT TO MODIFY: start the game\n",
    "     # TRY NOT TO MODIFY: start the game\n",
    "obs,info = envs.reset(seed=seed)\n",
    "rendered_image = envs.render()\n",
    "plt.imshow(rendered_image)\n",
    "#plt.xticks(range(0, rendered_image.shape[1], 1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--seed SEED]\n",
      "                             [--torch-deterministic [TORCH_DETERMINISTIC]]\n",
      "                             [--cuda [CUDA]] [--env-id ENV_ID]\n",
      "                             [--total-timesteps TOTAL_TIMESTEPS]\n",
      "                             [--buffer-size BUFFER_SIZE] [--gamma GAMMA]\n",
      "                             [--tau TAU] [--batch-size BATCH_SIZE]\n",
      "                             [--learning-starts LEARNING_STARTS]\n",
      "                             [--policy-lr POLICY_LR] [--q-lr Q_LR]\n",
      "                             [--policy-frequency POLICY_FREQUENCY]\n",
      "                             [--target-network-frequency TARGET_NETWORK_FREQUENCY]\n",
      "                             [--noise-clip NOISE_CLIP] [--alpha ALPHA]\n",
      "                             [--autotune [AUTOTUNE]] [--dropout DROPOUT]\n",
      "                             [--vehicles-count VEHICLES_COUNT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"41717560-a8a6-404b-a472-7f9da44c75b9\" --shell=9007 --transport=\"tcp\" --iopub=9009 --f=/Users/haridevaraj/Library/Jupyter/runtime/kernel-v2-636QJXziAarQAqV.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haridevaraj/opt/anaconda3/envs/volvo/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3405: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#args = parse_args()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()else \"cpu\")\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "args = parse_args()\n",
    "# exp_name = \"dddd\"\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "\n",
    "envs = make_env(args.env_id, args.seed)\n",
    "     # TRY NOT TO MODIFY: start the game\n",
    "     # TRY NOT TO MODIFY: start the game\n",
    "obs,info = envs.reset(seed=seed)\n",
    "    #print(info)\n",
    " \n",
    "    #print(\"obs1\",obs)\n",
    "    #print()\n",
    "   \n",
    "\n",
    "    \n",
    "ego_graph_data = create_whole_ego_bigraph_tensor_dynamic(obs)\n",
    "    \n",
    "    \n",
    "actor = Actor_GNN(envs,ego_graph_data,device)\n",
    "actor_eval = load_model(model_path=\"SAC_GNN_final_kinda/sac_gnn_2_öow/sac_gnn_expl20231007-102109.pt\",actor_network=actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_1= (actor_eval.gat_gnn_actor.conv1.att[0]).detach().cpu().numpy()\n",
    "att_2= (actor_eval.gat_gnn_actor.conv2.att[0]).detach().cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "volvo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
